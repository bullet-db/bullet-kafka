# These are required Kafka settings for consumers and producers.
# For more details see https://kafka.apache.org/documentation/#configuration.

# Common Kafka Properties
bullet.pubsub.kafka.bootstrap.servers: "localhost:9091"
bullet.pubsub.kafka.connections.max.idle.ms: "-1"

# Kafka Producer properties
# These are passed to KafkaProducer. You can add or override other Kafka properties by prefixing the property with "bullet.pubsub.kafka.producer.".
bullet.pubsub.kafka.producer.acks: "all"
bullet.pubsub.kafka.producer.retries: "5"
bullet.pubsub.kafka.producer.batch.size: "65536"
bullet.pubsub.kafka.producer.linger.ms: "5"
bullet.pubsub.kafka.producer.buffer.memory: "33554432"
bullet.pubsub.kafka.producer.request.timeout.ms: "3000"
bullet.pubsub.kafka.producer.key.serializer: "org.apache.kafka.common.serialization.StringSerializer"
bullet.pubsub.kafka.producer.value.serializer: "org.apache.kafka.common.serialization.ByteArraySerializer"
bullet.pubsub.kafka.producer.max.block.ms: "50000"

# Kafka Consumer properties
# These are passed to KafkaConsumer. You can add or override other Kafka properties by prefixing the property with "bullet.pubsub.kafka.consumer.".
bullet.pubsub.kafka.consumer.group.id: "bullet-query-consumer"
bullet.pubsub.kafka.consumer.heartbeat.interval.ms: "3000"
bullet.pubsub.kafka.consumer.enable.auto.commit: "true"
bullet.pubsub.kafka.consumer.auto.commit.interval.ms: "1000"
bullet.pubsub.kafka.consumer.session.timeout.ms: "30000"
bullet.pubsub.kafka.consumer.max.poll.records: "50"
bullet.pubsub.kafka.consumer.key.deserializer: "org.apache.kafka.common.serialization.StringDeserializer"
bullet.pubsub.kafka.consumer.value.deserializer: "org.apache.kafka.common.serialization.ByteArrayDeserializer"
bullet.pubsub.kafka.consumer.fetch.max.wait.ms: "500"
# These following are optional but must be greater than bullet.pubsub.sleep-ms in the web-service configuration if
# "bullet.pubsub.context.name" is QUERY_SUBMISSION.
bullet.pubsub.kafka.consumer.max.poll.interval.ms: "30000"
bullet.pubsub.kafka.consumer.request.timeout.ms: "35000"

# Kafka PubSub properties
# The number of messages that can be received before at least one commit is needed.
bullet.pubsub.kafka.subscriber.max.uncommitted.messages: 50
# Should the subscriber be rate limited
bullet.pubsub.kafka.subscriber.rate.limit.enable: false
# The maximum number of messages that will be read in a rate limit interval.
bullet.pubsub.kafka.subscriber.rate.limit.max.messages: 50
# The duration of a rate limit interval in milliseconds.
bullet.pubsub.kafka.subscriber.rate.limit.interval.ms: 10
bullet.pubsub.kafka.request.topic.name: "bullet.queries"
bullet.pubsub.kafka.response.topic.name: "bullet.responses"
# By default, the partition routing information is stored in the message metadata by the query publisher and used
# by the response publisher when sending back messages. If this is false, no routing information is stored, and Kafka
# decides which partitions responses are sent to.
bullet.pubsub.kafka.partition.routing.enable: true

# Optional settings:

# The following settings can be used when "SSL" is being used to authenticate with Kafka:
# bullet.pubsub.kafka.producer.security.protocol: "SSL"

# This class will automatically refresh certs in the Kafka client producer at a configurable interval
# bullet.pubsub.kafka.producer.ssl.engine.factory.class: "com.yahoo.bullet.kafka.CertRefreshingSSLEngineFactory"
# bullet.pubsub.kafka.producer.ssl.truststore.location: "my-truststore.jks"
# bullet.pubsub.kafka.producer.ssl.truststore.password: "changeit"
# bullet.pubsub.kafka.producer.ssl.cert.refreshing.cert.location: "my-cert.pem"
# bullet.pubsub.kafka.producer.ssl.cert.refreshing.key.location: "my-key.pem"
# bullet.pubsub.kafka.producer.ssl.cert.refreshing.refresh.interval.ms: 3600000

# This class will automatically refresh certs in the Kafka client consumer at a configurable interval
# bullet.pubsub.kafka.consumer.ssl.engine.factory.class: "com.yahoo.bullet.kafka.CertRefreshingSSLEngineFactory"
# bullet.pubsub.kafka.consumer.ssl.truststore.location: "my-truststore.jks"
# bullet.pubsub.kafka.consumer.ssl.truststore.password: "changeit"
# bullet.pubsub.kafka.consumer.ssl.cert.refreshing.cert.location: "my-cert.pem"
# bullet.pubsub.kafka.consumer.ssl.cert.refreshing.key.location: "my-key.pem"
# bullet.pubsub.kafka.consumer.ssl.cert.refreshing.refresh.interval.ms: 3600000

# The following settings are for partitioning. If not provided, the topics for requests and responses are fully used.
# If you've partitioned your request and response topics and want to spread them across web-service machines, you can
# configure the following when you set your "bullet.pubsub.context.name" to QUERY_SUBMISSION and
# "bullet.pubsub.class.name" to "com.yahoo.bullet.kafka.KafkaPubSub".

# This setting ensures that your publishers only write queries to these partitions.
#bullet.pubsub.kafka.request.partitions:
#  - 0
#  - 1
#  - 2
#  - 3

# This setting ensures that your consumers only listen to these partitions. Additionally, the producers will encode
# one of these partitions into their messages so that the results for their queries only arrive to these partitions.
#bullet.pubsub.kafka.response.partitions:
#  - 4
#  - 5
#  - 6
#  - 7

# These two settings together ensure that queries sent to a particular web-service instance will get their results
# sent to exactly the partitions that instance is reading from. You can use this to shard your web-service if you want
# to, by partitioning a mutually exclusive set of partitions for each instance. If you do not provide these settings, the
# entire topic is used. You can still shard the web-service but each instance will read all the messages but throw away
# the ones they do not know how to process. You can also leave out one of these settings to shard either the query
# writing or the result reading for a hybrid solution.
